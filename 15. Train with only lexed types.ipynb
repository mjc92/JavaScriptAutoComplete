{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "from packages.vocab import Vocab\n",
    "from packages.batch import Batch\n",
    "from models.lstm.model import RNNLM\n",
    "from slimit.lexer import Lexer\n",
    "from functions import detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Variable(torch.Tensor(np.arange(1000,dtype=float).reshape([10,20,-1]))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(100,size=(outputs.size(0),outputs.size(1)))\n",
    "c = np.vstack([np.sort(row) for row in b])\n",
    "d = np.array(c<50,dtype=int)\n",
    "targets = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 12, 14, 10,  8, 12,  8,  9, 14,  7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(targets!=0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "12\n",
      "14\n",
      "10\n",
      "8\n",
      "12\n",
      "8\n",
      "9\n",
      "14\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for i, length in enumerate((targets!=0).sum(1)):\n",
    "    print(length)\n",
    "    out.append(np.arange(0,length)+i*outputs.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.hstack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Valid = torch.LongTensor(valid).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lines = list((d!=0).sum(1).cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "for i, item in enumerate(d.sum(1)):\n",
    "    out_list.extend(list(np.arange(item,dtype=int)+i*a.size(1)))\n",
    "out_np = np.array(out_list,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.view(-1,1)[torch.LongTensor(out_np).cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.cuda().view(-1,a.size(2))[torch.LongTensor(out_np).cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8\n",
       " 12\n",
       " 14\n",
       " 10\n",
       "  8\n",
       " 12\n",
       "  8\n",
       "  9\n",
       " 14\n",
       "  7\n",
       "[torch.cuda.ByteTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(targets!=0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     1     2     3     4\n",
       "    5     6     7     8     9\n",
       "   10    11    12    13    14\n",
       "   15    16    17    18    19\n",
       "   20    21    22    23    24\n",
       "   25    26    27    28    29\n",
       "   30    31    32    33    34\n",
       "   35    36    37    38    39\n",
       "  100   101   102   103   104\n",
       "  105   106   107   108   109\n",
       "  110   111   112   113   114\n",
       "  115   116   117   118   119\n",
       "  120   121   122   123   124\n",
       "  125   126   127   128   129\n",
       "  130   131   132   133   134\n",
       "  135   136   137   138   139\n",
       "  140   141   142   143   144\n",
       "  145   146   147   148   149\n",
       "  150   151   152   153   154\n",
       "  155   156   157   158   159\n",
       "  200   201   202   203   204\n",
       "  205   206   207   208   209\n",
       "  210   211   212   213   214\n",
       "  215   216   217   218   219\n",
       "  220   221   222   223   224\n",
       "  225   226   227   228   229\n",
       "  230   231   232   233   234\n",
       "  235   236   237   238   239\n",
       "  240   241   242   243   244\n",
       "  245   246   247   248   249\n",
       "  250   251   252   253   254\n",
       "  255   256   257   258   259\n",
       "  260   261   262   263   264\n",
       "  265   266   267   268   269\n",
       "  300   301   302   303   304\n",
       "  305   306   307   308   309\n",
       "  310   311   312   313   314\n",
       "  315   316   317   318   319\n",
       "  320   321   322   323   324\n",
       "  325   326   327   328   329\n",
       "  330   331   332   333   334\n",
       "  335   336   337   338   339\n",
       "  340   341   342   343   344\n",
       "  345   346   347   348   349\n",
       "  400   401   402   403   404\n",
       "  405   406   407   408   409\n",
       "  410   411   412   413   414\n",
       "  415   416   417   418   419\n",
       "  420   421   422   423   424\n",
       "  425   426   427   428   429\n",
       "  430   431   432   433   434\n",
       "  435   436   437   438   439\n",
       "  500   501   502   503   504\n",
       "  505   506   507   508   509\n",
       "  510   511   512   513   514\n",
       "  515   516   517   518   519\n",
       "  520   521   522   523   524\n",
       "  525   526   527   528   529\n",
       "  530   531   532   533   534\n",
       "  535   536   537   538   539\n",
       "  540   541   542   543   544\n",
       "  545   546   547   548   549\n",
       "  550   551   552   553   554\n",
       "  555   556   557   558   559\n",
       "  600   601   602   603   604\n",
       "  605   606   607   608   609\n",
       "  610   611   612   613   614\n",
       "  615   616   617   618   619\n",
       "  620   621   622   623   624\n",
       "  625   626   627   628   629\n",
       "  630   631   632   633   634\n",
       "  635   636   637   638   639\n",
       "  700   701   702   703   704\n",
       "  705   706   707   708   709\n",
       "  710   711   712   713   714\n",
       "  715   716   717   718   719\n",
       "  720   721   722   723   724\n",
       "  725   726   727   728   729\n",
       "  730   731   732   733   734\n",
       "  735   736   737   738   739\n",
       "  740   741   742   743   744\n",
       "  800   801   802   803   804\n",
       "  805   806   807   808   809\n",
       "  810   811   812   813   814\n",
       "  815   816   817   818   819\n",
       "  820   821   822   823   824\n",
       "  825   826   827   828   829\n",
       "  830   831   832   833   834\n",
       "  835   836   837   838   839\n",
       "  840   841   842   843   844\n",
       "  845   846   847   848   849\n",
       "  850   851   852   853   854\n",
       "  855   856   857   858   859\n",
       "  860   861   862   863   864\n",
       "  865   866   867   868   869\n",
       "  900   901   902   903   904\n",
       "  905   906   907   908   909\n",
       "  910   911   912   913   914\n",
       "  915   916   917   918   919\n",
       "  920   921   922   923   924\n",
       "  925   926   927   928   929\n",
       "  930   931   932   933   934\n",
       "[torch.cuda.FloatTensor of size 102x5 (GPU 0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1,outputs.size(2))[Valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.random.randint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments related to the dataset\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# about running mode\n",
    "parser.add_argument(\"--mode\",type=str, help='whether \"train\" or \"test\" data')\n",
    "parser.add_argument(\"--dataset_name\",type=str, help='name of preprocessed dataset')\n",
    "parser.add_argument(\"--dataset_dir\",type=str, default= '/home/irteam/users/data/150kJavaScript/', \n",
    "                    help='name of preprocessed dataset')\n",
    "parser.add_argument(\"--startfrom\",type=int, default=0, help='whether starting from a previous model')\n",
    "\n",
    "\n",
    "# model information\n",
    "parser.add_argument(\"--embed_size\",type=int, default=128, help='embedding size')\n",
    "parser.add_argument(\"--hidden_size\",type=int, default=1024, help='hidden size')\n",
    "parser.add_argument(\"--num_layers\",type=int, default=1, help='number of LSTM layers')\n",
    "parser.add_argument(\"--num_epochs\",type=int, default=10, help='number of epochs to run')\n",
    "parser.add_argument(\"--batch_size\",type=int, default=100, help='size of minibatch')\n",
    "parser.add_argument(\"--seq_length\",type=int, default=50, help='length of sequence size')\n",
    "parser.add_argument(\"--lr\",type=float, default=0.002, help='learning rate size')\n",
    "parser.add_argument(\"--vocab_size\",type=int, default=50000, help='vocab_size')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# with open(os.path.join(args.dataset_dir,args.dataset_name,'list_of_files.txt')) as f:\n",
    "#     file_list = f.read().split('\\n')\n",
    "\n",
    "# batch = Batch(file_dir=args.dataset_dir,file_list=file_list,batch_size=args.batch_size,\n",
    "#               in_seq=args.seq_length,out_seq=args.seq_length)\n",
    "\n",
    "# idx2id = np.load('vocab/data_lexed/idx2id.npy').item()\n",
    "# idx2tok = np.load('vocab/data_lexed/idx2tok.npy').item()\n",
    "# idx2reg = np.load('vocab/data_lexed/idx2reg.npy').item()\n",
    "# word_list = [x for (_,x) in idx2tok.items()] + [x for (_,x) in idx2reg.items()][:1000] + \\\n",
    "#         [x for (_,x) in idx2id.items()][:args.vocab_size]\n",
    "# vocab = Vocab(args.vocab_size)\n",
    "# vocab.add_to_vocab(word_list)\n",
    "\n",
    "# import lexer\n",
    "lexer = Lexer()\n",
    "\n",
    "# load model\n",
    "if args.startfrom==0:    \n",
    "    model = RNNLM(vocab.max_size, embed_size=args.embed_size, hidden_size=args.hidden_size,\n",
    "                 num_layers = args.num_layers)\n",
    "else:\n",
    "    model = torch.load(os.path.join(args.dataset_dir)) # To-do\n",
    "model.cuda()\n",
    "\n",
    "# set loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "######################### training ###########################\n",
    "step = 99999\n",
    "if args.mode=='train':\n",
    "    for epoch in range(args.num_epochs):\n",
    "        batch.next_epoch(args.batch_size) # initialize batch data\n",
    "        batch.initialize_states(args.num_layers, args.hidden_size)\n",
    "        total_steps=step\n",
    "        step=0\n",
    "        while(batch.epoch_end==0):\n",
    "            step+=1\n",
    "            # update the minibatch inputs / outputs\n",
    "            model.zero_grad()\n",
    "            batch.get_minibatch(0)\n",
    "            inputs_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                                 line in batch.batch_in],dtype=int)\n",
    "            targets_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                                 line in batch.batch_out],dtype=int)\n",
    "            inputs = Variable(torch.LongTensor(inputs_np)).cuda()\n",
    "            targets = Variable(torch.LongTensor(targets_np)).cuda()\n",
    "\n",
    "            outputs, states = model(inputs,batch.states)\n",
    "            batch.states = detach(states)\n",
    "            loss = criterion(outputs, targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(),0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            batch.next_minibatch()\n",
    "            if step%100==0:\n",
    "                print ('Epoch [%d/%d], Loss: %.3f, Steps: [%d/%d], Perplexity: %5.2f' %\n",
    "               (epoch+1, num_epochs, loss.data[0], step, total_steps, np.exp(loss.data[0])))\n",
    "        torch.save(f='models/rnn_lm_types_3_epoch_%d.pckl'%(epoch+1),obj=model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Truncated Backpropagation \n",
    "def detach(states):\n",
    "    return [state.detach() for state in states] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "steps=99999\n",
    "for epoch in range(num_epochs):\n",
    "#     states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda(),\n",
    "#               Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda())\n",
    "    batch.next_epoch(batch_size)\n",
    "    batch.initialize_states(num_layers, hidden_size)\n",
    "    total_steps=steps\n",
    "    step=0\n",
    "    while(batch.epoch_end==0):\n",
    "        step+=1\n",
    "        # update the minibatch inputs / outputs\n",
    "        model.zero_grad()\n",
    "        batch.get_minibatch(0)\n",
    "        inputs_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                             line in batch.batch_in],dtype=int)\n",
    "        targets_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                             line in batch.batch_out],dtype=int)\n",
    "        inputs = Variable(torch.LongTensor(inputs_np)).cuda()\n",
    "        targets = Variable(torch.LongTensor(targets_np)).cuda()\n",
    "        \n",
    "        outputs, states = model(inputs,batch.states)\n",
    "        batch.states = detach(states)\n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(),0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch.next_minibatch()\n",
    "        if step%100==0:\n",
    "            print ('Epoch [%d/%d], Loss: %.3f, Steps: [%d/%d], Perplexity: %5.2f' %\n",
    "           (epoch+1, num_epochs, loss.data[0], step, total_steps, np.exp(loss.data[0])))\n",
    "    torch.save(f='models/rnn_lm_types_2_epoch_%d.pckl'%(epoch+1),obj=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#     with open(train_path+'list_of_files.txt') as f:\n",
    "#         input_files = f.readlines()\n",
    "#     i = 0\n",
    "#     for file in input_files:\n",
    "#         i+=1\n",
    "#         with open(train_path+file.strip()) as f:\n",
    "#             lines = f.readlines()\n",
    "#         out_lines = []\n",
    "#         for line in lines:\n",
    "#             line = line.strip()\n",
    "#             out_lines.append(vocab.word_list_to_idx_list(line.split())[:50])\n",
    "#         batch_size = len(lines)\n",
    "#         ids = torch.LongTensor(np.array(out_lines[:batch_size]))\n",
    "#         states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda(),\n",
    "#                   Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda())\n",
    "\n",
    "# #     for i in range(0, ids.size(1) - seq_length, seq_length):\n",
    "# #         # Get batch inputs and targets\n",
    "#         inputs = Variable(ids[:, :seq_length-1]).cuda()\n",
    "#         targets = Variable(ids[:, 1:seq_length].contiguous()).cuda()\n",
    "        \n",
    "#         # Forward + Backward + Optimize\n",
    "#         model.zero_grad()\n",
    "#         states = detach(states)\n",
    "#         outputs, states = model(inputs, states) \n",
    "#         loss = criterion(outputs, targets.view(-1))\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda(),\n",
    "          Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H2 = torch.chunk(H,batch.batch_size,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling\n",
    "sample_path = '/home/irteam/users/data/150kJavaScript/samples.txt'\n",
    "with open(sample_path, 'w') as f:\n",
    "    # Set intial hidden ane memory states\n",
    "    state = (Variable(torch.zeros(num_layers, 1, hidden_size)).cuda(),\n",
    "         Variable(torch.zeros(num_layers, 1, hidden_size)).cuda())\n",
    "\n",
    "    # Select one word id randomly\n",
    "    prob = torch.ones(vocab_size)\n",
    "    input = Variable(torch.multinomial(prob, num_samples=1).unsqueeze(1),\n",
    "                     volatile=True).cuda()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Forward propagate rnn \n",
    "        output, state = model(input, state)\n",
    "        \n",
    "        # Sample a word id\n",
    "        prob = output.squeeze().data.exp().cpu()\n",
    "        word_id = torch.multinomial(prob, 1)[0]\n",
    "        \n",
    "        # Feed sampled word id to next time step\n",
    "        input.data.fill_(word_id)\n",
    "        \n",
    "        # File write\n",
    "        word = corpus.dictionary.idx2word[word_id]\n",
    "        word = '\\n' if word == '<eos>' else word + ' '\n",
    "        f.write(word)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Sampled [%d/%d] words and save to %s'%(i+1, num_samples, sample_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "for epoch in range(1):\n",
    "#     states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda(),\n",
    "#               Variable(torch.zeros(num_layers, batch_size, hidden_size)).cuda())\n",
    "    batch.next_epoch(batch_size)\n",
    "    batch.initialize_states(num_layers, hidden_size)\n",
    "    step=0\n",
    "    while(batch.epoch_end==0):\n",
    "        step+=1\n",
    "        # update the minibatch inputs / outputs\n",
    "        batch.get_minibatch(0)\n",
    "        inputs_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                             line in batch.batch_in],dtype=int)\n",
    "        targets_np = np.array([vocab.word_list_to_idx_list(line) for\n",
    "                             line in batch.batch_in],dtype=int)\n",
    "        inputs = Variable(torch.LongTensor(inputs_np)).cuda()\n",
    "        targets = Variable(torch.LongTensor(targets_np)).cuda()\n",
    "        \n",
    "        outputs, states = model(inputs,batch.states)\n",
    "        batch.states = detach(states)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = outputs.view(batch_size,seq_length,-1).max(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(targets)):\n",
    "    line0 = inputs[i]\n",
    "    line1 = targets[i]\n",
    "    line2 = out[i]\n",
    "    print(''.join(vocab.idx_list_to_word_list(line0.cpu().data.numpy())))    \n",
    "    print(''.join(vocab.idx_list_to_word_list(line1.cpu().data.numpy())))\n",
    "    print(''.join(vocab.idx_list_to_word_list(line2.cpu().data.numpy())))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_np = ids.cpu().numpy()\n",
    "targets_np = targets.cpu().data.numpy()\n",
    "predicted_np = predicted_outs.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(targets.size(0)):\n",
    "    print(vocab.idx_list_to_word_list(inputs_np[i]))\n",
    "    print(vocab.idx_list_to_word_list(predicted_np[i]))\n",
    "    print(vocab.idx_list_to_word_list(targets_np[i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
